Wed May 25 18:35:37 2022

targets_one_hot is the one hot encoding for angle. ex: [1 0 1]

Shape of waves is: torch.Size([514, 1024])
Datatype of waves is: torch.float32
waves requires grad: False
Shape of targets is: torch.Size([514])
Datatype of targets is: torch.int64
targets requires grad: False
Ex: 0
Shape of targets_one_hot is: torch.Size([514, 6])
Datatype of targets_one_hot is: torch.float32
targets_one_hot requires grad: False
Ex: tensor([1, 0, 0, 0, 0, 0])

AcousticEmissionDataset loaded in!

Parameters:
time_stamp : 20220525_18-35-37
SIG_LEN : 1024
DT : 1e-07
LOW_PASS : 50000
HIGH_PASS : 800000
FFT_UNITS : 1000
NUM_BINS : 26
EPOCHS : 3000
LEARNING_RATE : 0.001
BATCH_SIZE : 20
train_seed : 41
train_percent : 0.1
test_percent : 0.9
total_count : 514
train_count : 51
test_count : 463
angles : ['20deg' '22deg' '26deg' '30deg' '36deg' '40deg']
feature_dim : 1024
num_classes : 6

Shape of x batch is: torch.Size([20, 1024])
Datatype of x batch is: torch.float32

Shape of y batch is: torch.Size([20, 6])
Datatype of y batch is: torch.float32

------------------------------------------------------------------
Begin model training...

NeuralNetwork_01(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=10, bias=True)
    (1): ReLU()
    (2): Linear(in_features=10, out_features=6, bias=True)
  )
)

Begin Training...

Testing loss at Epoch #  0 is :  0.4799867868423462
Testing loss at Epoch #  50 is :  0.25734394788742065
Testing loss at Epoch #  100 is :  0.21490266919136047
Testing loss at Epoch #  150 is :  0.18862175941467285
Testing loss at Epoch #  200 is :  0.18263885378837585
Testing loss at Epoch #  250 is :  0.15928353369235992
Testing loss at Epoch #  300 is :  0.1516244113445282
Testing loss at Epoch #  350 is :  0.15337657928466797
Testing loss at Epoch #  400 is :  0.14468137919902802
Testing loss at Epoch #  450 is :  0.12427657097578049
Testing loss at Epoch #  500 is :  0.11817396432161331
Testing loss at Epoch #  550 is :  0.12037280201911926
Testing loss at Epoch #  600 is :  0.10050423443317413
Testing loss at Epoch #  650 is :  0.11552092432975769
Testing loss at Epoch #  700 is :  0.11000075936317444
Testing loss at Epoch #  750 is :  0.10463259369134903
Testing loss at Epoch #  800 is :  0.10841547697782516
Testing loss at Epoch #  850 is :  0.09780395030975342
Testing loss at Epoch #  900 is :  0.0984373688697815
Testing loss at Epoch #  950 is :  0.08898130059242249
Testing loss at Epoch #  1000 is :  0.08899067342281342
Testing loss at Epoch #  1050 is :  0.08818415552377701
Testing loss at Epoch #  1100 is :  0.08003661036491394
Testing loss at Epoch #  1150 is :  0.09211470186710358
Testing loss at Epoch #  1200 is :  0.08674856275320053
Testing loss at Epoch #  1250 is :  0.0837966576218605
Testing loss at Epoch #  1300 is :  0.08226463198661804
Testing loss at Epoch #  1350 is :  0.08137037605047226
Testing loss at Epoch #  1400 is :  0.0818067416548729
Testing loss at Epoch #  1450 is :  0.07510966062545776
Testing loss at Epoch #  1500 is :  0.07232349365949631
Testing loss at Epoch #  1550 is :  0.07356206327676773
Testing loss at Epoch #  1600 is :  0.07016359269618988
Testing loss at Epoch #  1650 is :  0.0701756626367569
Testing loss at Epoch #  1700 is :  0.07006615400314331
Testing loss at Epoch #  1750 is :  0.06487590074539185
Testing loss at Epoch #  1800 is :  0.07233448326587677
Testing loss at Epoch #  1850 is :  0.0697760283946991
Testing loss at Epoch #  1900 is :  0.06701242178678513
Testing loss at Epoch #  1950 is :  0.07117605954408646
Testing loss at Epoch #  2000 is :  0.06092502176761627
Testing loss at Epoch #  2050 is :  0.06751522421836853
Testing loss at Epoch #  2100 is :  0.06225087493658066
Testing loss at Epoch #  2150 is :  0.06463932991027832
Testing loss at Epoch #  2200 is :  0.06290046125650406
Testing loss at Epoch #  2250 is :  0.059281669557094574
Testing loss at Epoch #  2300 is :  0.06915502995252609
Testing loss at Epoch #  2350 is :  0.0628870353102684
Testing loss at Epoch #  2400 is :  0.06447964906692505
Testing loss at Epoch #  2450 is :  0.06170252338051796
Testing loss at Epoch #  2500 is :  0.06331589072942734
Testing loss at Epoch #  2550 is :  0.055120062083005905
Testing loss at Epoch #  2600 is :  0.05779014155268669
Testing loss at Epoch #  2650 is :  0.06425897032022476
Testing loss at Epoch #  2700 is :  0.06316161155700684
Testing loss at Epoch #  2750 is :  0.060467399656772614
Testing loss at Epoch #  2800 is :  0.059604667127132416
Testing loss at Epoch #  2850 is :  0.05434752255678177
Testing loss at Epoch #  2900 is :  0.06125997006893158
Testing loss at Epoch #  2950 is :  0.05902396887540817
Testing loss at Epoch #  3000 is :  0.054875366389751434
Training completed.

------------------------------------------------------------------
Begin model evaluation...


Evaluate results on test data...

class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 4 , target=4
class_prediction= 3 , target=4
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 5 , target=3
class_prediction= 4 , target=2
class_prediction= 4 , target=4
class_prediction= 1 , target=0
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=4
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 4 , target=3
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 3 , target=2
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 5 , target=4
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 1 , target=3
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 4 , target=3
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 4 , target=0
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 5 , target=4
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 3 , target=4
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=4
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 4 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=1
class_prediction= 4 , target=5
class_prediction= 4 , target=4
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 1 , target=0
class_prediction= 4 , target=1
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 4 , target=4
class_prediction= 1 , target=0
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=4
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 4 , target=3
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 4 , target=2
class_prediction= 0 , target=4
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 4 , target=3
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 4 , target=0
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 5 , target=4
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=2
class_prediction= 1 , target=3
class_prediction= 1 , target=2
class_prediction= 1 , target=0
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 2 , target=0
class_prediction= 1 , target=0
class_prediction= 2 , target=2
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 4 , target=3
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 5 , target=3
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=4
class_prediction= 0 , target=0
class_prediction= 5 , target=4
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 1 , target=3
class_prediction= 1 , target=2
class_prediction= 4 , target=3
class_prediction= 4 , target=2
class_prediction= 1 , target=1
class_prediction= 0 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 1 , target=2
class_prediction= 4 , target=4
class_prediction= 4 , target=4
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=0
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 0 , target=0
class_prediction= 1 , target=2
class_prediction= 4 , target=4
class_prediction= 5 , target=4
class_prediction= 3 , target=3
class_prediction= 5 , target=4
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=3
class_prediction= 5 , target=0
class_prediction= 4 , target=3
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 5 , target=3
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 4 , target=3
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 5 , target=3
class_prediction= 4 , target=3
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 4 , target=3
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 3 , target=3
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 4 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 4 , target=5
class_prediction= 3 , target=5
class_prediction= 0 , target=2
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 0 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=4
class_prediction= 1 , target=1
class_prediction= 4 , target=5
class_prediction= 5 , target=5
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 4 , target=2
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 1 , target=2
class_prediction= 5 , target=4
class_prediction= 1 , target=2
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 5 , target=4
class_prediction= 1 , target=0
class_prediction= 4 , target=3
class_prediction= 0 , target=0
class_prediction= 4 , target=3
class_prediction= 4 , target=4
class_prediction= 5 , target=5
class_prediction= 3 , target=3
class_prediction= 5 , target=5
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 4 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 5 , target=5
class_prediction= 4 , target=4
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 5 , target=5
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 0 , target=0
class_prediction= 4 , target=4
class_prediction= 0 , target=2
class_prediction= 1 , target=0

Test Set Metrics:
              precision    recall  f1-score   support

       20deg       0.81      0.89      0.85        63
       22deg       0.97      0.50      0.66       153
       26deg       0.09      0.88      0.16         8
       30deg       0.71      0.90      0.80        61
       36deg       0.80      0.72      0.76        90
       40deg       0.94      0.85      0.89        88

    accuracy                           0.72       463
   macro avg       0.72      0.79      0.69       463
weighted avg       0.86      0.72      0.76       463


Saved PyTorch Model State to nn01_3000_0.001_adam_mse.pth

Saved data to nn01_3000_0.001_adam_mse.pkl

Completed training and evaluation.

