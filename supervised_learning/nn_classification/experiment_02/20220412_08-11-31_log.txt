Tue Apr 12 08:11:31 2022

Shape of waves is: torch.Size([657, 1024])
Datatype of waves is: torch.float32
waves requires grad: False
Shape of targets is: torch.Size([657, 4])
Datatype of targets is: torch.float32
targets requires grad: False

Parameters:
time_stamp : 20220412_08-11-31
SIG_LEN : 1024
DT : 1e-07
LOW_PASS : 50000
HIGH_PASS : 800000
FFT_UNITS : 1000
NUM_BINS : 26
EPOCHS : 5000
LEARNING_RATE : 0.001
BATCH_SIZE : 20
train_seed : 42
train_percent : 0.5
test_percent : 0.5
total_count : 657
train_count : 328
test_count : 329
angles : ['20deg' '26deg' '30deg' '40deg']
feature_dim : 1024
num_classes : 4

Shape of x batch is: torch.Size([20, 1024])
Datatype of x batch is: torch.float32

Shape of y batch is: torch.Size([20, 4])
Datatype of y batch is: torch.float32

------------------------------------------------------------------
Begin model training...

NeuralNetwork_01(
  (layers): Sequential(
    (0): Linear(in_features=1024, out_features=10, bias=True)
    (1): ReLU()
    (2): Linear(in_features=10, out_features=4, bias=True)
  )
)

Begin Training...

Testing loss at Epoch #  0 is :  3.642303228378296
Testing loss at Epoch #  50 is :  1.8053406476974487
Testing loss at Epoch #  100 is :  1.406206488609314
Testing loss at Epoch #  150 is :  1.3483408689498901
Testing loss at Epoch #  200 is :  1.3338474035263062
Testing loss at Epoch #  250 is :  1.298691987991333
Testing loss at Epoch #  300 is :  1.299259901046753
Testing loss at Epoch #  350 is :  1.2583132982254028
Testing loss at Epoch #  400 is :  1.2639039754867554
Testing loss at Epoch #  450 is :  1.2772367000579834
Testing loss at Epoch #  500 is :  1.2524815797805786
Testing loss at Epoch #  550 is :  1.2632250785827637
Testing loss at Epoch #  600 is :  1.215667486190796
Testing loss at Epoch #  650 is :  1.2300734519958496
Testing loss at Epoch #  700 is :  1.2353804111480713
Testing loss at Epoch #  750 is :  1.2403979301452637
Testing loss at Epoch #  800 is :  1.2286913394927979
Testing loss at Epoch #  850 is :  1.2186431884765625
Testing loss at Epoch #  900 is :  1.2137181758880615
Testing loss at Epoch #  950 is :  1.2143014669418335
Testing loss at Epoch #  1000 is :  1.2323616743087769
Testing loss at Epoch #  1050 is :  1.2158366441726685
Testing loss at Epoch #  1100 is :  1.2145367860794067
Testing loss at Epoch #  1150 is :  1.1986737251281738
Testing loss at Epoch #  1200 is :  1.2364643812179565
Testing loss at Epoch #  1250 is :  1.213120698928833
Testing loss at Epoch #  1300 is :  1.2123104333877563
Testing loss at Epoch #  1350 is :  1.2001655101776123
Testing loss at Epoch #  1400 is :  1.186824917793274
Testing loss at Epoch #  1450 is :  1.1918458938598633
Testing loss at Epoch #  1500 is :  1.1766695976257324
Testing loss at Epoch #  1550 is :  1.1873105764389038
Testing loss at Epoch #  1600 is :  1.2128766775131226
Testing loss at Epoch #  1650 is :  1.1949121952056885
Testing loss at Epoch #  1700 is :  1.1991907358169556
Testing loss at Epoch #  1750 is :  1.1993941068649292
Testing loss at Epoch #  1800 is :  1.1968750953674316
Testing loss at Epoch #  1850 is :  1.2022655010223389
Testing loss at Epoch #  1900 is :  1.1597633361816406
Testing loss at Epoch #  1950 is :  1.1776689291000366
Testing loss at Epoch #  2000 is :  1.1711450815200806
Testing loss at Epoch #  2050 is :  1.1994065046310425
Testing loss at Epoch #  2100 is :  1.192144513130188
Testing loss at Epoch #  2150 is :  1.1668899059295654
Testing loss at Epoch #  2200 is :  1.172835111618042
Testing loss at Epoch #  2250 is :  1.1867610216140747
Testing loss at Epoch #  2300 is :  1.1894763708114624
Testing loss at Epoch #  2350 is :  1.1561834812164307
Testing loss at Epoch #  2400 is :  1.1703715324401855
Testing loss at Epoch #  2450 is :  1.1789867877960205
Testing loss at Epoch #  2500 is :  1.1535429954528809
Testing loss at Epoch #  2550 is :  1.1773180961608887
Testing loss at Epoch #  2600 is :  1.1718071699142456
Testing loss at Epoch #  2650 is :  1.1729309558868408
Testing loss at Epoch #  2700 is :  1.1836374998092651
Testing loss at Epoch #  2750 is :  1.198167085647583
Testing loss at Epoch #  2800 is :  1.1802325248718262
Testing loss at Epoch #  2850 is :  1.1776549816131592
Testing loss at Epoch #  2900 is :  1.1567037105560303
Testing loss at Epoch #  2950 is :  1.1688920259475708
Testing loss at Epoch #  3000 is :  1.1626499891281128
Testing loss at Epoch #  3050 is :  1.1655611991882324
Testing loss at Epoch #  3100 is :  1.18924081325531
Testing loss at Epoch #  3150 is :  1.1803655624389648
Testing loss at Epoch #  3200 is :  1.1526941061019897
Testing loss at Epoch #  3250 is :  1.138119101524353
Testing loss at Epoch #  3300 is :  1.197440266609192
Testing loss at Epoch #  3350 is :  1.164963960647583
Testing loss at Epoch #  3400 is :  1.1884679794311523
Testing loss at Epoch #  3450 is :  1.1608139276504517
Testing loss at Epoch #  3500 is :  1.1530427932739258
Testing loss at Epoch #  3550 is :  1.1722007989883423
Testing loss at Epoch #  3600 is :  1.1723347902297974
Testing loss at Epoch #  3650 is :  1.1490819454193115
Testing loss at Epoch #  3700 is :  1.156604528427124
Testing loss at Epoch #  3750 is :  1.1910117864608765
Testing loss at Epoch #  3800 is :  1.1720330715179443
Testing loss at Epoch #  3850 is :  1.1473028659820557
Testing loss at Epoch #  3900 is :  1.1564819812774658
Testing loss at Epoch #  3950 is :  1.1420800685882568
Testing loss at Epoch #  4000 is :  1.1577057838439941
Testing loss at Epoch #  4050 is :  1.1462327241897583
Testing loss at Epoch #  4100 is :  1.1473865509033203
Testing loss at Epoch #  4150 is :  1.1435240507125854
Testing loss at Epoch #  4200 is :  1.155619740486145
Testing loss at Epoch #  4250 is :  1.1589325666427612
Testing loss at Epoch #  4300 is :  1.1543872356414795
Testing loss at Epoch #  4350 is :  1.1649150848388672
Testing loss at Epoch #  4400 is :  1.1648470163345337
Testing loss at Epoch #  4450 is :  1.1487603187561035
Testing loss at Epoch #  4500 is :  1.152532696723938
Testing loss at Epoch #  4550 is :  1.1468793153762817
Testing loss at Epoch #  4600 is :  1.1542736291885376
Testing loss at Epoch #  4650 is :  1.1292990446090698
Testing loss at Epoch #  4700 is :  1.142098069190979
Testing loss at Epoch #  4750 is :  1.1303035020828247
Testing loss at Epoch #  4800 is :  1.1675677299499512
Testing loss at Epoch #  4850 is :  1.1423693895339966
Testing loss at Epoch #  4900 is :  1.1555438041687012
Testing loss at Epoch #  4950 is :  1.1543396711349487
Testing loss at Epoch #  5000 is :  1.1403288841247559
Training completed.

------------------------------------------------------------------
Begin model evaluation...


Evaluate results on test data...

class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 3 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 0 , target=2
class_prediction= 3 , target=2
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 3 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 3 , target=2
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 3 , target=2
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 2 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 3 , target=2
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 2 , target=0
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 3 , target=0
class_prediction= 3 , target=2
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 0 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=2
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 3 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 3 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 0 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 2 , target=2
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 1 , target=1
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 1 , target=1
class_prediction= 3 , target=2
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 2 , target=2
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 0 , target=0
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 3 , target=2
class_prediction= 3 , target=3
class_prediction= 3 , target=3
class_prediction= 0 , target=0
class_prediction= 3 , target=3
class_prediction= 1 , target=1
class_prediction= 0 , target=0

Test Set Metrics:
              precision    recall  f1-score   support

       20deg       0.96      0.96      0.96        67
       26deg       0.97      0.97      0.97       117
       30deg       0.67      0.96      0.79        51
       40deg       0.97      0.74      0.84        94

    accuracy                           0.90       329
   macro avg       0.89      0.91      0.89       329
weighted avg       0.92      0.90      0.90       329


Saved PyTorch Model State to nn01_5000_0.001_adam_mse.pth

Saved data to nn01_5000_0.001_adam_mse.pkl

Completed training and evaluation.

